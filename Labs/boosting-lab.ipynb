{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting Lab\n",
    "Practice tuning hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosting have the following parameters:\n",
    "* loss function\n",
    "* number of trees\n",
    "* shrinkage or learning rate (default around 0.1)\n",
    "* tree depth (good value 2,3,4)\n",
    "* subsampling rate (default around 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the help of the code below create the following plots:\n",
    "* Compare the validation /test error of adaboost and gradient boosting with logloss as a function of the number of trees [1 .. 2000]. (use stumps, learning rate = 0.1)\n",
    "* Compare the test error gradient boosting for various values of tree depth (1,3,5,10) as a function of the number of trees (use learning rate = 0.1)\n",
    "* Compare the test error gradient boosting for various values of learning rate (use your favorite tree depth)\n",
    "* Experiment with various values of subsampling rate (0.2, 0.5, 0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct dataset\n",
    "X, y = make_hastie_10_2(random_state=0)\n",
    "X_train, X_val = X[:2000], X[2000:]\n",
    "y_train, y_val = y[:2000], y[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 10)\n",
      "[ 1. -1.  1. ..., -1. -1.  1.]\n",
      "[[ 1.76405235  0.40015721  0.97873798  2.2408932   1.86755799 -0.97727788\n",
      "   0.95008842 -0.15135721 -0.10321885  0.4105985 ]]\n"
     ]
    }
   ],
   "source": [
    "print X.shape\n",
    "print y\n",
    "print X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.6071 0.6475\n",
      "200 0.6546 0.6875\n",
      "300 0.6881 0.7285\n",
      "400 0.7191 0.76\n",
      "500 0.735 0.781\n",
      "600 0.7505 0.7995\n",
      "700 0.7605 0.8115\n",
      "800 0.7697 0.8185\n",
      "900 0.7763 0.829\n",
      "1000 0.785 0.8395\n",
      "1100 0.7905 0.8445\n",
      "1200 0.7932 0.8455\n",
      "1300 0.8008 0.8535\n",
      "1400 0.8062 0.8625\n",
      "1500 0.8091 0.865\n",
      "1600 0.8133 0.8665\n",
      "1700 0.8153 0.8715\n",
      "1800 0.8186 0.8755\n",
      "1900 0.8152 0.867\n",
      "2000 0.8235 0.8825\n",
      "2100 0.8242 0.88\n",
      "2200 0.8286 0.8855\n",
      "2300 0.8292 0.8885\n",
      "2400 0.8324 0.889\n",
      "2500 0.8339 0.893\n"
     ]
    }
   ],
   "source": [
    "# Adaboost\n",
    "# How do you find the best value of the number of trees?\n",
    "for i in range(25):\n",
    "    n = 100 * (i + 1) \n",
    "    bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                             algorithm=\"SAMME\", learning_rate=.1,\n",
    "                             n_estimators=n).fit(X_train, y_train)\n",
    "# prediction accuracy\n",
    "    print n, bdt.score(X_val, y_val), bdt.score(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.8907 0.9975\n",
      "200 0.9002 1.0\n",
      "300 0.9047 1.0\n",
      "400 0.9063 1.0\n",
      "500 0.9082 1.0\n",
      "600 0.9067 1.0\n",
      "700 0.9063 1.0\n",
      "800 0.9077 1.0\n",
      "900 0.9072 1.0\n",
      "1000 0.9069 1.0\n",
      "1100 0.9072 1.0\n",
      "1200 0.9074 1.0\n",
      "1300 0.9071 1.0\n",
      "1400 0.9063 1.0\n",
      "1500 0.9063 1.0\n",
      "1600 0.9063 1.0\n",
      "1700 0.9063 1.0\n",
      "1800 0.9063 1.0\n",
      "1900 0.9063 1.0\n",
      "2000 0.9063 1.0\n",
      "2100 0.9063 1.0\n",
      "2200 0.9063 1.0\n",
      "2300 0.9063 1.0\n",
      "2400 0.9063 1.0\n",
      "2500 0.9063 1.0\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classfier\n",
    "\n",
    "for i in range(25):\n",
    "    n = 100 * (i + 1) \n",
    "    clf = GradientBoostingClassifier(n_estimators=n, learning_rate=0.1, \\\n",
    "                                     max_depth=4, random_state=0).fit(X_train, y_train)\n",
    "# prediction accuracy\n",
    "    print n, clf.score(X_val, y_val), clf.score(X_train, y_train) #overfitting with max_depth=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  3.  3. ...,  3.  3.  3.]\n"
     ]
    }
   ],
   "source": [
    "N, _ = X_train.shape\n",
    "d = 3 * np.ones(N)\n",
    "print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6411"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to change weights to training points\n",
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "dt.fit(X_train, y_train, sample_weight=d)\n",
    "dt.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58050000000000002"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.ones(N)\n",
    "dt = DecisionTreeClassifier(max_depth=2)\n",
    "dt.fit(X_train, y_train, sample_weight=d)\n",
    "dt.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
