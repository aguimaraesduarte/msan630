{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **Lab 1: Recommendation System and Matrix Factorization**\n",
    " \n",
    "*Part 1:* Topic extraction with NMF\n",
    "\n",
    " *Part 2:* Gradient Descent of MF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Topic extraction with NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of applying Non-negative Matrix Factorization on a corpus of documents and extract additive models of the topic structure of the corpus. The output is a list of topics, each represented as a list of terms (weights are not shown).\n",
    "\n",
    "The default parameters (n_samples / n_features / n_topics) should make the example runnable in a couple of tens of seconds. You can try to increase the dimensions of the problem, but be aware that the time complexity is polynomial in NMF. \n",
    "\n",
    "References:\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/applications/topics_extraction_with_nmf_lda.html\n",
    "http://scikit-learn.org/stable/modules/decomposition.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Lars Buitinck <L.J.Buitinck@uva.nl>\n",
    "#         Chyi-Kwei Yau <chyikwei.yau@gmail.com>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_topics = 10\n",
    "n_top_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"sklearn.datasets.twenty_newsgroups\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 66.965s.\n"
     ]
    }
   ],
   "source": [
    "# Load the 20 newsgroups dataset and vectorize it. We use a few heuristics\n",
    "# to filter out useless terms early on: the posts are stripped of headers,\n",
    "# footers and quoted replies, and common English words, words occurring in\n",
    "# only one document or in at least 95% of the documents are removed.\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "data_samples = dataset.data\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"Well i'm not sure about the story nad it did seem biased. What\\nI disagree with is your statement that the U.S. Media is out to\\nruin Israels reputation. That is rediculous. The U.S. media is\\nthe most pro-israeli media in the world. Having lived in Europe\\nI realize that incidences such as the one described in the\\nletter have occured. The U.S. media as a whole seem to try to\\nignore them. The U.S. is subsidizing Israels existance and the\\nEuropeans are not (at least not to the same degree). So I think\\nthat might be a reason they report more clearly on the\\natrocities.\\n\\tWhat is a shame is that in Austria, daily reports of\\nthe inhuman acts commited by Israeli soldiers and the blessing\\nreceived from the Government makes some of the Holocaust guilt\\ngo away. After all, look how the Jews are treating other races\\nwhen they got power. It is unfortunate.\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_samples[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n",
      "done in 3.044s.\n"
     ]
    }
   ],
   "source": [
    "# Use tf-idf features for NMF.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x39115 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 56 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 33831)\t0.0670739217313\n",
      "  (0, 33307)\t0.0944452134759\n",
      "  (0, 24262)\t0.165390978626\n",
      "  (0, 12059)\t0.0633334912554\n",
      "  (0, 6935)\t0.122123425772\n",
      "  (0, 12220)\t0.106451924325\n",
      "  (0, 33080)\t0.09176839573\n",
      "  (0, 22786)\t0.397352856718\n",
      "  (0, 30569)\t0.152250856945\n",
      "  (0, 19582)\t0.323869349055\n",
      "  (0, 29725)\t0.135654431165\n",
      "  (0, 29228)\t0.161934674527\n",
      "  (0, 27819)\t0.098878623467\n",
      "  (0, 19576)\t0.206962724505\n",
      "  (0, 38004)\t0.0731453984357\n",
      "  (0, 17294)\t0.0743825035025\n",
      "  (0, 21515)\t0.106116390108\n",
      "  (0, 14135)\t0.106451924325\n",
      "  (0, 29036)\t0.0996903702203\n",
      "  (0, 18665)\t0.169621152966\n",
      "  (0, 11803)\t0.102632391061\n",
      "  (0, 21231)\t0.101040643532\n",
      "  (0, 25282)\t0.129617443792\n",
      "  (0, 35470)\t0.0717655732032\n",
      "  (0, 18368)\t0.111681219525\n",
      "  :\t:\n",
      "  (0, 29673)\t0.0970408767494\n",
      "  (0, 9204)\t0.0949920933722\n",
      "  (0, 5926)\t0.132066934927\n",
      "  (0, 31583)\t0.132066934927\n",
      "  (0, 6040)\t0.139110735264\n",
      "  (0, 11106)\t0.113802868546\n",
      "  (0, 29679)\t0.0983193738145\n",
      "  (0, 18960)\t0.154248196089\n",
      "  (0, 4301)\t0.106451924325\n",
      "  (0, 9608)\t0.147277168158\n",
      "  (0, 32431)\t0.11080947107\n",
      "  (0, 7165)\t0.152250856945\n",
      "  (0, 29102)\t0.09574670796\n",
      "  (0, 16568)\t0.0762486505076\n",
      "  (0, 22208)\t0.0793842747072\n",
      "  (0, 17780)\t0.126942990227\n",
      "  (0, 16885)\t0.132066934927\n",
      "  (0, 6175)\t0.0782804259703\n",
      "  (0, 21661)\t0.0697085775742\n",
      "  (0, 19850)\t0.095650721991\n",
      "  (0, 35309)\t0.129617443792\n",
      "  (0, 28724)\t0.13818581093\n",
      "  (0, 16546)\t0.0677869256762\n",
      "  (0, 27476)\t0.0749522114694\n",
      "  (0, 36008)\t0.130200787922\n"
     ]
    }
   ],
   "source": [
    "print(tfidf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model with tf-idf features,n_samples=2000 and n_features=1000...\n",
      "done in 1.859s.\n"
     ]
    }
   ],
   "source": [
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model with tf-idf features,\"\n",
    "      \"n_samples=%d and n_features=%d...\" % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_topics, random_state=1, alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model:\n",
      "Topic #0:\n",
      "don people just like think know good time ve right make say want really did way new use going ll\n",
      "Topic #1:\n",
      "windows file dos files window program use running version ms using problem server pc screen ftp run os application software\n",
      "Topic #2:\n",
      "god jesus bible christ faith believe christians christian heaven sin hell life church truth lord say belief does existence man\n",
      "Topic #3:\n",
      "geb dsl chastity n3jxp cadre shameful pitt intellect skepticism surrender gordon banks soon edu lyme blood weight patients medical probably\n",
      "Topic #4:\n",
      "key chip encryption clipper keys escrow government algorithm security secure encrypted public nsa des enforcement law bit privacy secret use\n",
      "Topic #5:\n",
      "drive scsi ide drives disk hard controller floppy hd cd mac boot rom cable internal tape bus seagate bios quantum\n",
      "Topic #6:\n",
      "game team games players hockey year season play win league teams nhl baseball player detroit toronto runs pitching best playoffs\n",
      "Topic #7:\n",
      "thanks mail does know advance hi info looking anybody address appreciated help email information send ftp post interested list appreciate\n",
      "Topic #8:\n",
      "israel israeli jews arab arabs lebanese lebanon peace israelis jewish adam palestinian palestinians war land attacks syria palestine state occupied\n",
      "Topic #9:\n",
      "card video monitor vga bus drivers cards color driver ram ati mode memory isa pc graphics vesa vlb diamond bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "print(\"\\nTopics in NMF model:\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01525578,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.0401674 ,  0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here are the weights of this document in the 10 topics\n",
    "# note that they are sparse\n",
    "nmf.transform(tfidf[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy multiplication refresher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It is convention to import NumPy with the alias np\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[ 5 10 15]\n"
     ]
    }
   ],
   "source": [
    "# numpy array with the values 1, 2, 3\n",
    "data1 = np.array([1, 2, 3])\n",
    "# Perform the scalar product of 5 and the numpy array\n",
    "data2 = 5 * data1\n",
    "print(data1)\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]]\n",
      "[[0 1]\n",
      " [2 3]]\n",
      "[[ 2  3]\n",
      " [ 6 11]\n",
      " [10 19]]\n"
     ]
    }
   ],
   "source": [
    "# np.dot give the regular matrix multiplication\n",
    "A = np.arange(6).reshape((3,2))\n",
    "B = np.arange(4).reshape((2,2))\n",
    "print(A)\n",
    "print(B)\n",
    "print(np.dot(A,B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[0 1 2 3 4]\n",
      "[ 0  1  4  9 16]\n"
     ]
    }
   ],
   "source": [
    "# * gives element wise multiplication\n",
    "a = np.arange(5)\n",
    "b = np.arange(5)\n",
    "print(a)\n",
    "print(b)\n",
    "print(a*b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent of MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 1 4 5 1]\n",
      " [0 5 2 1 4]\n",
      " [1 4 1 1 2]\n",
      " [4 1 5 5 4]\n",
      " [5 3 4 5 4]\n",
      " [1 5 1 1 1]\n",
      " [5 1 0 5 4]]\n",
      "(7, 5)\n"
     ]
    }
   ],
   "source": [
    "# Use the following matrix as an example. Here 0 means \"empty\". Use k = 2\n",
    "Y = np.array([[5, 1, 4, 5, 1], [0, 5, 2, 1, 4], [1, 4, 1, 1, 2],\\\n",
    "              [4, 1, 5, 5, 4], [5, 3, 4, 5, 4], [1, 5, 1, 1, 1], \\\n",
    "              [5, 1, 0, 5, 4]])\n",
    "print(Y)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize the random matrices U and V\n",
    "n, m = Y.shape\n",
    "k = 2\n",
    "U = np.random.uniform(0, 1, size=n*k).reshape(n,k)\n",
    "V = np.random.uniform(0, 1, size=m*k).reshape(m,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "R = (Y == 0).astype(int)\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "N = np.sum(Y > 0)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.90708295  0.68240166]\n",
      " [ 0.78080046  0.47960558]\n",
      " [ 0.78175046  0.62386719]\n",
      " [ 0.85073205  0.2470913 ]\n",
      " [ 0.19957364  0.78864122]\n",
      " [ 0.84365199  0.90094208]\n",
      " [ 0.83929014  0.97663157]]\n",
      "[[ 0.45212418  0.75575085]\n",
      " [ 0.35006305  0.01482054]\n",
      " [ 0.90718219  0.76978735]\n",
      " [ 0.50597835  0.60867363]\n",
      " [ 0.99909563  0.78987642]]\n"
     ]
    }
   ],
   "source": [
    "print(U)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_hat = np.dot(U, V.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute Mean square error between Y and Y_hat (hint: you have to use R, use matrix operations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given U and V compute a gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply gradient descent to this problem for 500 iterations with \n",
    "# learning rate 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "name": "ML_lab1_review_student",
  "notebookId": 4025,
  "toc": {
   "nav_menu": {
    "height": "85px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
